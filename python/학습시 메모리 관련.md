# 1. 개요

torch 기반 학습시 메모리가 과하게 축적되는 경우가 있음

## 1.1. 원인

### 1.1.1. 결과 메모리 미반환

학습 모델의 결과 데이터는 보통 바로 메모리를 반환하지만, 다른곳에 사용되는 경우 메모리가 미반환되게 된다.

```python
pred = pred.to('cpu').detach().numpy() # 메모리 해제
```

그럴때는 cpu 로 옮겨서 메모리를 해제해줘야 한다.

# 2. 명령어

## 2.1. 분류

### 2.1.1. 상세 분류(설명)

